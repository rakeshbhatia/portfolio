<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Project - Collecting NBA Player Data from ESPN</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!--<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>

    <link rel="stylesheet" href="highlight/styles/default.css">
    <script src="highlight/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>-->

    <link href="css/prism.css" rel="stylesheet" />
    <link href="css/syntax.css" rel="stylesheet" />

    <!--<link rel="stylesheet" href="css/pygments14.css" type="text/css" />-->
    <!--<link rel="stylesheet" href="css/pygments.css" type="text/css" />-->
</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <!-- <a class="navbar-brand" href="index.html">Start Bootstrap</a> -->
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="index.html">Home</a>
                    </li>
                    <li>
                        <a href="about.html">About</a>
                    </li>
                    <!--<li>
                        <a href="project1.html">Project 1</a>
                    </li>-->
                    <!--<li>
                        <a href="contact.html">Contact</a>
                    </li>-->
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('img/home-bg.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="page-heading">
                        <h1>Python Blog</h1>
                        <hr class="small">
                        <span class="subheading">Building a Daily Fantasy Basketball Framework with Python: Part 1</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <p>The last couple years have seen me dabbling in daily fantasy sports (dfs) - mostly in basketball, since it's my
                  favorite sport, but a little bit of football as well. My experience playing in a few daily fantasy
                  contests on Fanduel and DraftKings exposed me to just how competitive and and lucrative this industry
                  really is. There are a frequent number of contests with thousands upon thousands of participants, with
                  cash prizes that can exceed hundreds of thousands of dollars - <strong>for a single contest</strong>!
                  Initially I realized that it was incredibly hard to casually pick a lineup of players purely based
                  on your "intuition"; very rarely would you be able to win money this way. You need to develop some type
                  of predictive framework that can help you collect data on different players, and make predictions about
                  how they will perform, based on various metrics. This post is part 1 in a series that focuses on creating
                  such a framework for daily fantasy basketball, but the basic framework and methodology can be modified and
                  extended for other sports as well. I would recommend having some prior familiarity with daily fantasy sports
                  in order to get the maximum benefit out of this post, in terms of how it applies to learning and using Python.</p>
                <p>Basketball is, of course, a very simple sport. Simple in its objective, but complicated in its execution.
                  They also say that the NBA is very predictable. This is somewhat misleading - yes, the game is fairly
                  predictable from a team perspective, as in you know who are the top teams every year that are likely to win
                  a championship and/or win many regular season games. However, on an individual basis the sport is not
                  nearly as predictable as one might guess. Even the top players - who are generally very consistent from game
                  to game - can have wild fluctuations in their performance due to various factors. Being able to gauge the
                  likelihood of some of these fluctuations goes a long way toward being a winning daily fantasy basketball
                  player. The key to winning money lies in being able to predict the <strong>unpredictable</strong>. This,
                  obviously, is what separates the winners from the pack. Anybody can predict that LeBron James will most
                  likely play well on any given night, but who's going to be the lucky person that rosters Allen Crabbe
                  when he's priced at the minimum and somehow explodes for 30 fantasy points off the bench?</p>
                <p>In order to make the process of creating lineups for daily fantasy basketball easier, you need to have
                  some sort of baseline framework in place that can help you make decisions. Basketball may be a predictable
                  sport, but how do you analyze all the metrics involved in making player predictions? There are nearly 400
                  players in the NBA, and each player can play a maximum of 82 games per year. That's a lot of data. In this
                  article, which is part 1 in a series, I will focus on how you can use Python to easily collect and store data
                  for all NBA players. Once the data is in place (i.e., in a CSV file), you can easily run other tools on the
                  data to figure out different types of trends and characteristics for each player.</p>
                <p>For example, you could write a script to determine whether a player plays better against a particular team
                  when he faces them on the road, as opposed to at home. Many daily fantasy sites have such frameworks in place
                  and charge a hefty fee per month for you to use their sophisticated tools and projection systems. Why pay them
                  when you can create a reasonable facsimile of their tools for your own usage? After all, statistical data on any
                  athlete is readily available on the web. For this exercise, we will use ESPN for obtaining the NBA player data.
                  Anyone who has read my previous two posts know that I am pretty gung-ho about web scraping. When I first started
                  playing around with web scraping, I felt like a kid in a toy store. It's an incredibly powerful tool which, if used
                  responsibly, can help automate and streamline a variety of different data analysis tasks. Obviously, learning from
                  a particular set of data is at the heart of any statistical analysis. But you need some way of getting the data
                  first - and presenting it in a form which is easily usable. This is what I will discuss in this post, which is part
                  1 in a series on using Python for daily fantasy basketball.</p>
                <p>If you already read my previous scraping-related blogs, which focused on data collection for the stock market,
                  then you already have a pretty good idea of how to use BeautifulSoup, Selenium and PhantomJS for scraping both
                  HTML and JavaScript content. However, if you didn't, I suggest checkout out the BeautifulSoup documentation
                  <a href="#">here</a>, which is a good place to start with web scraping.</p>
                <pre><code class="language-python"></code></pre>

                <p>Now, let's install Selenium and PhantomJS using Brew:</p>

                <pre><code class="language-python"></code></pre>

                <p>Awesome. Now that we have our required utilities set up, we need to inspect the HTML source code for the
                javascript-rendered site that we want to scrape. If you just try to view the source, you will only see the
                javascript sections added under the <code>script</code> tag. We need to inspect the source in order to see
                the javascript executed and loaded as HTML. Then we must navigate through the web of nested HTML tags in order
                to find the content we are looking for. The resulting HTML after javascript content is loaded is usually quite
                complex and intricate, much more so than a bare-bones HTML webpage (this makes intuitive sense, since javascript
                handles more complex tasks than those which can be done by HTML alone).</p>

                <img src="img/yahoo-finance-screenshot-1.jpg" alt="yahoo inspect screenshot 1" style='height: 100%; width: 100%; object-fit: contain'/>

                <p>Running your cursor over different sections of the webpage will highlight the sections of code that correspond
                  to it. Let's try to navigate our way to where the value for "Beta" is contained. Don't worry too much about the
                  strange tag id's; we're only concerned with finding the specific tags that we need. For now, we'll focus on just
                  grabbing this one piece of information - the stock's beta value - to demonstrate the power of Selenium and PhantomJS.
                  Afterwards, you can extrapolate it to whatever content you want to scrape. In order to obtain the element that we want,
                  the easiest way is to use the XPath for that element. Right-click the line of code corresponding to your desired element,
                  select "Copy", and then select "Copy XPath". This will copy the XPath variable to the clipboard, which we can then use
                  in our Python script. I would suggest pasting the XPath in a safe place, perhaps a simple text file, so that you can
                  retrieve it later.</p>

                <img src="img/yahoo-finance-screenshot-2.jpg" alt="yahoo inspect screenshot 2" style='height: 100%; width: 100%; object-fit: contain'/>

                <p>Now we can start writing our scraper. Unlike my last post, which contained more complex data structures, here we'll just define
                  one <code>StockQuote</code> class to illustrate the power of Selenium and PhantomJS.</p>


                <pre><code class="language-python">class StockQuote:
    def __init__(self, symbol, company):
        self.symbol = symbol
        self.company = company

    def scrape_yahoo(self, div=0):
        # Start with Yahoo's base URL format and use string replace for our current stock symbol
        url = 'http://finance.yahoo.com/quote/%s/key-statistics?p=%s/' % (self.symbol, self.symbol)

        # Instantiate the driver
        driver = webdriver.PhantomJS()
        driver.get(url)
        driver.implicitly_wait(20)

        # Use the XPath to get Beta value
        elem = driver.find_element_by_xpath("//*[@id='main-0-Quote-Proxy']/section/div[2]/section/div/section/div[2]/div[2]/div/div[1]/table/tbody/tr[1]/td[2]")

        # Store the value
        self.beta = elem.text</code></pre>

                <p>The <code>StockQuote</code> class is relatively simple, with the constructor setting the <code>self.symbol</code>
                  and <code>self.company</code> variables to the values that are passed in. The interesting part of the code begins
                  with the <code>scrape_yahoo()</code> function. First, we need to define our <code>url</code> string. The Yahoo URL
                  that stores key statistics for a particular stock contains the stock symbol twice, which is how each URL differentiates
                  itself from each other. Therefore, we just use string replace to set the unique <code>url</code> string for each stock.</p>
                <p>Now for the tricky part. In order to utilize PhantomJS, we need to instantiate a <code>driver</code> by using the base
                  call to <code>webdriver.PhantomJS()</code>. PhantomJS is essentially a headless WebKit for website testing. This means that
                  it essentially uses a "virtual" browser rather than actually opening up the browser interface. This enables much faster unit
                  tests for websites, since the overhead of browser startup and shutdown is avoided. We need to call the <code>get()</code>
                  member function belonging to <code>driver</code>, passing our <code>url</code> variable in as the main argument. Its
                  generally a good practice to add a specified wait time, especially if you are scraping many different URLs at once. Let's
                  take a closer look at the next line of code.</p>
                  <pre><code class="language-python"># Use the XPath to get Beta value
elem = driver.find_element_by_xpath("//*[@id='main-0-Quote-Proxy']/section/div[2]/section/div/section/div[2]/div[2]/div/div[1]/table/tbody/tr[1]/td[2]")</code></pre>
                <p>We use the <code>find_element_by_xpath()</code> method to extract the element corresponding to a particular XPath. Take a
                  second to notice the way the XPath string is structured - its essentially the HTML directory tree for the element we are
                  scraping. This is why the last part of the XPath string is <code>/table/tbody/tr[1]/td[2]</code> which corresponds to the HTML source
                  we inspected when looking at Yahoo's website. The stock's Beta value is stored in the second td element, which is why the XPath
                  ends in <code>td[2]</code>.</p>
                <p>Once we instantiate <code>elem</code> to the element we are extracting, we can access its <code>text</code> member variable to
                  extract the string that is stored under that tag. We can then simply store <code>elem.text</code> within the <code>StockQuote</code>
                  member variable <code>self.beta</code>. Let's run a simple test case in our <code>main</code> method to see if the program correctly
                  scrapes the Beta value for Apple stock (ticker symbol: AAPL).</p>
                <pre><code class="language-python">def main():
    # Test out one quote to see if correct text is returned
    my_quote = StockQuote('AAPL', 'Apple')
    my_quote.scrape_yahoo()
    print my_quote.beta

if __name__ == '__main__':
    sys.exit(main())</code></pre>
                <p>We create a new <code>StockQuote</code> object and name it <code>my_quote</code>, and call the <code>scrape_yahoo()</code> method.
                  We can run the program to see the output printed to the console:</p>
                <img src="img/yahoo-scraper-console-screenshot.jpg" alt="yahoo scraper console screenshot" style='height: 100%; width: 100%; object-fit: contain'/>
                <p>Sure enough, the beta value printed out matches correctly with the value 1.45 listed on the Yahoo page. Hopefully you can now realize
                  the power of Python with Selenium and PhantomJS to scrape javascript-embedded content from the web, among its many other uses. You can just
                  follow the same steps outlined in this post for each piece of data you need to scrape. If you wanted to scrape the beta value for many different
                  stocks at once, for example, the corresponding XPath should be the same for each stock quote's Yahoo page. Thus, you could just put everything in
                  a <code>for</code> loop and simply make sure to change the value of <code>url</code> every time. Be sure to check out the
                  <a href="https://github.com/rakeshbhatia/stock-market-data" style="color:teal">Github</a> repository if you want to download the source code for
                  yourself. Thanks for reading!</p>
            </div>
        </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted">Copyright &copy; Rakesh Bhatia 2017</p>
                </div>
            </div>

            <div class="col-lg-8">
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

    <script src="js/prism.js"></script>
</body>

</html>
